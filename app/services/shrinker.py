import json
import time
from typing import Optional, List, Dict

from app.core.logger import get_logger
from app.models.tenders import TenderPositions
from app.services.attrs_standardizer import AttrsStandardizer
from app.services.trigrammer import Trigrammer
from app.services.unit_standardizer import UnitStandardizer
from app.services.vectorizer import SemanticMatcher

logger = get_logger(name=__name__)


class Shrinker:
    def __init__(
        self,
        trigrammer: Optional[Trigrammer] = None,
        vectorizer: Optional[SemanticMatcher] = None,
        attrs_sorter: Optional[AttrsStandardizer] = None,
        unit_normalizer: Optional[UnitStandardizer] = None,
    ):
        self.trigrammer = trigrammer
        self.vectorizer = vectorizer
        self.attrs_sorter = attrs_sorter
        self.unit_normalizer = unit_normalizer

    async def shrink(self, candidates: dict, position: TenderPositions):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"""

        # === –≠–¢–ê–ü 1: –ü–û–î–ì–û–¢–û–í–ö–ê ===
        logger.warning("=" * 60)
        logger.warning("–ù–ê–ß–ê–õ–û –û–ë–†–ê–ë–û–¢–ö–ò –ü–û–ó–ò–¶–ò–ò")
        logger.warning("=" * 60)

        position_max_points = len(position.attributes)
        min_required_points = position_max_points // 2  # –ü–æ–ª–æ–≤–∏–Ω–∞ –æ—Ç –º–∞–∫—Å–∏–º—É–º–∞

        logger.info(f"üìã –ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏: {position.title}")
        logger.info(f"üìã –ö–∞—Ç–µ–≥–æ—Ä–∏—è –ø–æ–∑–∏—Ü–∏–∏: {position.category}")
        logger.info(f"üéØ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –±–∞–ª–ª—ã: {position_max_points}")
        logger.info(f"‚ö° –ú–∏–Ω–∏–º—É–º –¥–ª—è –ø—Ä–æ—Ö–æ–¥–∞: {min_required_points}")

        # –ü–∞—Ä—Å–∏–º –∞—Ç—Ä–∏–±—É—Ç—ã –ø–æ–∑–∏—Ü–∏–∏
        position_parsed_attrs = await self._parse_position_attributes(
            position.attributes
        )

        if not position_parsed_attrs:
            logger.warning("‚ùå –ù–µ—Ç –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
            return

        # === –≠–¢–ê–ü 2: –û–ë–†–ê–ë–û–¢–ö–ê –ö–ê–ù–î–ò–î–ê–¢–û–í ===
        logger.info(
            f"\nüîç –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(candidates['hits']['hits'])} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"
        )

        processed_candidates = []
        unmatched_characteristics = set()

        for idx, candidate in enumerate(candidates["hits"]["hits"]):
            logger.info(
                f"\n--- –ö–∞–Ω–¥–∏–¥–∞—Ç {idx + 1}: {candidate['_source']['title']} ---"
            )

            result = await self._process_single_candidate(
                candidate,
                position_parsed_attrs,
                min_required_points,
                unmatched_characteristics,
            )

            if result:
                processed_candidates.append(result)

        # === –≠–¢–ê–ü 3: –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê ===
        await self._finalize_results(
            candidates,
            processed_candidates,
            unmatched_characteristics,
            position,
            min_required_points,
        )

        # logger.critical(f'–£—Ö–æ–¥–∏–º –≤ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Å–æ–Ω, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≤–µ—Ä—à–∏—Ç—å —Ç–∞—Å–∫—É –∫—Ä–æ–ª–∏–∫–∞...')
        # while True:
        #     time.sleep(100000)

    async def _parse_position_attributes(self, attributes) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –ø–æ–∑–∏—Ü–∏–∏"""
        logger.info("\nüìù –ü–ê–†–°–ò–ù–ì –ê–¢–†–ò–ë–£–¢–û–í –ü–û–ó–ò–¶–ò–ò:")

        # üîç –î–ï–¢–ê–õ–¨–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê attrs_sorter
        logger.info(
            f"üîß attrs_sorter api_url: {getattr(self.attrs_sorter, 'api_url', 'NOT_SET')}"
        )

        # üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—ã—Ä—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–∞—Ö
        logger.info(f"üìä Total attributes count: {len(attributes)}")
        for i, attr in enumerate(attributes):
            logger.info(
                f"üìä Attr {i+1}: name='{attr.name}', value='{attr.value}', type='{getattr(attr, 'type', 'NO_TYPE')}', unit='{getattr(attr, 'unit', 'NO_UNIT')}'"
            )


        parsed_attrs = []

        for i, attr in enumerate(attributes):
            logger.info(f"\n--- –ê–¢–†–ò–ë–£–¢ {i+1}/{len(attributes)} ---")
            try:
                parsed = None
                try:
                    unit = attr.unit
                    raw_string = f"{attr.name}: {attr.value} {unit}"
                    logger.info(f"üîÑ Raw request: {raw_string}")
                    parsed = await self.attrs_sorter.extract_attr_data(raw_string)
                    logger.info(f"üîÑ Raw response: {parsed}")
                except Exception as e:
                    logger.error(f"failed: {e}")

                if parsed and len(parsed) > 0:
                    parsed_data = {
                        "original": attr,
                        "parsed": parsed[0],
                        "display_name": f"{attr.name}: {attr.value}",
                    }
                    parsed_attrs.append(parsed_data)

                    logger.info(f"  - –¢–∏–ø: {parsed[0].get('type', 'unknown')}")
                    logger.info(f"  - –ó–Ω–∞—á–µ–Ω–∏–µ: {parsed[0].get('value', 'unknown')}")
                else:
                    logger.warning(f"‚ùå Final parsed result: {parsed} | {attr.name}, {attr.value}")

            except Exception as e:
                logger.error(f"CRITICAL ERROR for '{attr.name}': {e}")
                logger.error(f"Exception type: {type(e)}")

        logger.info(f"\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        logger.info(f"üìä –í—Å–µ–≥–æ –∞—Ç—Ä–∏–±—É—Ç–æ–≤: {len(attributes)}")
        logger.info(f"üìä –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—à–µ–Ω–æ: {len(parsed_attrs)}")
        logger.info(f"üìä –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å: {len(attributes) - len(parsed_attrs)}")

        return parsed_attrs

    async def _process_single_candidate(
        self,
        candidate: Dict,
        position_attrs: List[Dict],
        min_required_points: int,
        unmatched_characteristics: set,
    ) -> Optional[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞"""

        candidate_title = candidate["_source"]["title"]
        candidate_attrs = candidate["_source"].get("attributes", [])

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result = {
            "candidate": candidate,
            "points": 0,
            "max_points": len(position_attrs),
            "matched_attributes": [],
            "unmatched_attributes": [],
            "early_exit": False,
        }

        logger.info(f'üîé –ö–∞—Ç–µ–≥–æ—Ä–∏—è yandex: {candidate["_source"]["yandex_category"]} | –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {candidate["_source"]["category"]} | –∫–æ–ª-–≤–æ –∞—Ç—Ä–∏–±—É—Ç–æ–≤: {len(candidate_attrs)}')

        # –ü–∞—Ä—Å–∏–º –∞—Ç—Ä–∏–±—É—Ç—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
        candidate_parsed_attrs = await self._parse_candidate_attributes(candidate_attrs)
        logger.warning(f'candidate parsed attrs:')
        for attr in candidate_parsed_attrs:
            logger.warning(f'{attr}')

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –∞—Ç—Ä–∏–±—É—Ç –ø–æ–∑–∏—Ü–∏–∏
        for pos_attr in position_attrs:
            match_found = await self._find_attribute_match(
                pos_attr, candidate_parsed_attrs, result
            )

            if match_found:
                result["points"] += 1
                logger.info(f"  ‚úÖ +1 –±–∞–ª–ª –∑–∞: {pos_attr['display_name']}")
            else:
                result["unmatched_attributes"].append(pos_attr["display_name"])
                unmatched_characteristics.add(pos_attr["display_name"])
                logger.info(f"  ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {pos_attr['display_name']}")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–Ω–Ω–µ–≥–æ –≤—ã—Ö–æ–¥–∞
            remaining_attrs = (
                len(position_attrs)
                - len(result["matched_attributes"])
                - len(result["unmatched_attributes"])
            )
            max_possible_points = result["points"] + remaining_attrs

            if max_possible_points < min_required_points:
                logger.warning(
                    f"  ‚ö° –†–∞–Ω–Ω–∏–π –≤—ã—Ö–æ–¥: –º–∞–∫—Å–∏–º—É–º –≤–æ–∑–º–æ–∂–Ω—ã—Ö –±–∞–ª–ª–æ–≤ {max_possible_points} < {min_required_points}"
                )
                result["early_exit"] = True
                break

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        logger.info(f"üìà –ò—Ç–æ–≥–æ–≤—ã–π —Å—á–µ—Ç: {result['points']}/{result['max_points']}")

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–∏–Ω–∏–º—É–º—É –±–∞–ª–ª–æ–≤
        if result["points"] < min_required_points:
            logger.warning(
                f"‚ùå –ö–∞–Ω–¥–∏–¥–∞—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω: {result['points']} < {min_required_points}"
            )
            return None

        logger.info(f"‚úÖ –ö–∞–Ω–¥–∏–¥–∞—Ç –ø—Ä–∏–Ω—è—Ç!")
        return result

    async def _parse_candidate_attributes(
        self, candidate_attrs: List[Dict]
    ) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ (–æ–Ω–∏ —É–∂–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!)"""
        parsed_attrs = []

        logger.info(
            f"üîÑ Parsing {len(candidate_attrs)} candidate attributes (already processed)"
        )

        for attr in candidate_attrs:
            try:
                # –ê—Ç—Ä–∏–±—É—Ç—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –£–ñ–ï –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ê–ù–´ –≤ Elasticsearch
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–µ standardized –ø–æ–ª—è
                standardized_name = attr.get(
                    "standardized_name", attr.get("original_name", "")
                )
                standardized_value = attr.get(
                    "standardized_value", attr.get("original_value", "")
                )
                if attr.get('attribute_type', 'simple') == 'simple':
                    standardized_unit = attr.get("standardized_unit")
                else:
                    standardized_unit = attr.get("standardized_value")[0].get("unit")

                attribute_type = attr.get("attribute_type", "simple")

                # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é —Å attrs_sorter
                parsed_structure = {
                    "name": standardized_name,
                    "type": attribute_type,
                    "value": self._convert_to_attrs_sorter_format(
                        standardized_value, standardized_unit, attribute_type
                    ),
                }

                parsed_attrs.append(
                    {
                        "original": attr,
                        "parsed": parsed_structure,
                        "display_name": f"{standardized_name}: {standardized_value}",
                    }
                )

                logger.debug(
                    f"‚úÖ Converted: {standardized_name} = {standardized_value} (type: {attribute_type})"
                )

            except Exception as e:
                logger.error(f"üí• –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—Ç—Ä–∏–±—É—Ç–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞: {e}")

        logger.info(f"üìä Converted {len(parsed_attrs)} candidate attributes")
        return parsed_attrs

    def _convert_to_attrs_sorter_format(self, value, unit, attr_type):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç attrs_sorter"""
        try:
            if attr_type == "simple":
                return {"value": value, "unit": unit}

            elif attr_type == "range":
                # value —É–∂–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                if isinstance(value, list) and len(value) == 2:
                    return [
                        {
                            "value": (
                                value[0].get("value")
                                if isinstance(value[0], dict)
                                else value[0]
                            ),
                            "unit": unit,
                        },
                        {
                            "value": (
                                value[1].get("value")
                                if isinstance(value[1], dict)
                                else value[1]
                            ),
                            "unit": unit,
                        },
                    ]
                else:
                    # Fallback: –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ –¥–∏–∞–ø–∞–∑–æ–Ω
                    return [
                        {"value": value, "unit": unit},
                        {"value": value, "unit": unit},
                    ]

            elif attr_type == "multiple":
                # value —É–∂–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º
                if isinstance(value, list):
                    return [
                        {
                            "value": (
                                item.get("value") if isinstance(item, dict) else item
                            ),
                            "unit": unit,
                        }
                        for item in value
                    ]
                else:
                    return [{"value": value, "unit": unit}]

            else:
                # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ simple
                return {"value": value, "unit": unit}

        except Exception as e:
            logger.error(f"Error converting value {value}: {e}")
            return {"value": str(value), "unit": unit}

    async def _find_attribute_match(
        self, pos_attr: Dict, candidate_attrs: List[Dict], result: Dict
    ) -> bool:
        """–ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∞—Ç—Ä–∏–±—É—Ç–∞ –ø–æ–∑–∏—Ü–∏–∏ —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞"""

        pos_type = pos_attr["parsed"].get("type")
        pos_name = pos_attr["parsed"].get("name", "")

        for cand_attr in candidate_attrs:
            cand_type = cand_attr["parsed"].get("type")
            cand_name = cand_attr["parsed"].get("name", "")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
            name_similarity = await self._check_name_similarity(pos_name, cand_name)
            # logger.warning(name_similarity)
            if name_similarity < 0.6:  # –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–π
                continue

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –ø–æ —Ç–∏–ø—É –∏ –∑–Ω–∞—á–µ–Ω–∏—é
            value_match = await self._check_value_compatibility(
                pos_attr["parsed"], cand_attr["parsed"]
            )

            if value_match:
                result["matched_attributes"].append(
                    {
                        "position_attr": pos_attr["display_name"],
                        "candidate_attr": cand_attr["display_name"],
                        "name_similarity": name_similarity,
                        "match_type": f"{pos_type} vs {cand_type}",
                    }
                )
                return True

        return False

    async def _check_name_similarity(self, name1: str, name2: str) -> float:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–π –∞—Ç—Ä–∏–±—É—Ç–æ–≤"""
        try:
            if not name1 or not name2:
                return 0.0

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏
            similarity = await self.vectorizer.compare_two_strings(name1, name2)
            return similarity

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π: {e}")
            return 0.0

    async def _check_value_compatibility(
        self, pos_parsed: Dict, cand_parsed: Dict
    ) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏–π –∞—Ç—Ä–∏–±—É—Ç–æ–≤"""
        pos_type = pos_parsed.get("type")
        cand_type = cand_parsed.get("type")

        try:
            # –ü—Ä–æ—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            if pos_type == "simple" and cand_type == "simple":
                return await self._compare_simple_values(pos_parsed, cand_parsed)

            # –î–∏–∞–ø–∞–∑–æ–Ω—ã
            elif pos_type == "range" and cand_type == "range":
                return await self._compare_ranges(pos_parsed, cand_parsed)

            # –ó–Ω–∞—á–µ–Ω–∏–µ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
            elif pos_type == "simple" and cand_type == "range":
                return await self._value_in_range(pos_parsed, cand_parsed)

            elif pos_type == "range" and cand_type == "simple":
                return await self._value_in_range(cand_parsed, pos_parsed)

            # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            elif "multiple" in [pos_type, cand_type]:
                return await self._compare_multiple_values(pos_parsed, cand_parsed)

            return False

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏–π: {e}")
            return False

    async def _compare_simple_values(self, pos_data: Dict, cand_data: Dict) -> bool:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
        pos_value = pos_data.get("value", {}).get("value")
        cand_value = cand_data.get("value", {}).get("value")

        if isinstance(pos_value, str) and isinstance(cand_value, str):
            # –¢–µ–∫—Å—Ç–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            similarity = await self.vectorizer.compare_two_strings(
                pos_value, cand_value
            )
            return similarity >= 0.8

        elif isinstance(pos_value, (int, float)) and isinstance(
            cand_value, (int, float)
        ):
            # –ß–∏—Å–ª–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            return await self._compare_numeric_values(pos_data, cand_data)

        elif isinstance(pos_value, bool) and isinstance(cand_value, bool):
            # –ë—É–ª–µ–≤–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            return pos_value == cand_value

        return False

    async def _compare_numeric_values(self, pos_data: Dict, cand_data: Dict) -> bool:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Å —É—á–µ—Ç–æ–º –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è"""
        pos_value = pos_data.get("value", {}).get("value")
        cand_value = cand_data.get("value", {}).get("value")
        pos_unit = pos_data.get("value", {}).get("unit")
        cand_unit = cand_data.get("value", {}).get("unit")

        try:
            # –ï—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü—ã –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç
            if pos_unit == cand_unit:
                tolerance = 0.1  # 10% –¥–æ–ø—É—Å–∫
                return (
                    abs(pos_value - cand_value) / max(pos_value, cand_value, 1)
                    <= tolerance
                )

            # –ï—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü—ã —Ä–∞–∑–Ω—ã–µ - –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
            if pos_unit and cand_unit:
                pos_normalized = await self.unit_normalizer.normalize_unit(
                    str(pos_value), pos_unit
                )
                cand_normalized = await self.unit_normalizer.normalize_unit(
                    str(cand_value), cand_unit
                )

                if pos_normalized.get("success") and cand_normalized.get("success"):
                    pos_norm_val = pos_normalized.get("normalized_value")
                    cand_norm_val = cand_normalized.get("normalized_value")

                    if pos_norm_val is not None and cand_norm_val is not None:
                        tolerance = 0.1
                        return (
                            abs(pos_norm_val - cand_norm_val)
                            / max(pos_norm_val, cand_norm_val, 1)
                            <= tolerance
                        )

            return False

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {e}")
            return False

    async def _compare_ranges(self, pos_data: Dict, cand_data: Dict) -> bool:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤"""
        try:
            pos_range = pos_data.get("value", [])
            cand_range = cand_data.get("value", [])

            if len(pos_range) < 2 or len(cand_range) < 2:
                return False

            pos_start = pos_range[0].get("value")
            pos_end = pos_range[1].get("value")
            cand_start = cand_range[0].get("value")
            cand_end = cand_range[1].get("value")

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–µ–π
            if pos_start == "_inf-":
                pos_start = float("-inf")
            if pos_end == "_inf+":
                pos_end = float("inf")
            if cand_start == "_inf-":
                cand_start = float("-inf")
            if cand_end == "_inf+":
                cand_end = float("inf")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
            return pos_start <= cand_end and cand_start <= pos_end

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤: {e}")
            return False

    @staticmethod
    async def _value_in_range(value_data: Dict, range_data: Dict) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–∏—Ç –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω"""
        try:
            value = value_data.get("value", {}).get("value")
            range_vals = range_data.get("value", [])

            if len(range_vals) < 2:
                return False

            start = range_vals[0].get("value")
            end = range_vals[1].get("value")

            if start == "_inf-":
                start = float("-inf")
            if end == "_inf+":
                end = float("inf")

            return start <= value <= end

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ: {e}")
            return False

    async def _compare_multiple_values(self, pos_data: Dict, cand_data: Dict) -> bool:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
        try:
            pos_values = pos_data.get("value", [])
            cand_values = cand_data.get("value", [])

            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
            if not isinstance(pos_values, list):
                pos_values = [pos_values]
            if not isinstance(cand_values, list):
                cand_values = [cand_values]

            # –ò—â–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
            for pos_val in pos_values:
                pos_val_str = str(pos_val.get("value", pos_val)).lower()
                for cand_val in cand_values:
                    cand_val_str = str(cand_val.get("value", cand_val)).lower()

                    similarity = await self.vectorizer.compare_two_strings(
                        pos_val_str, cand_val_str
                    )
                    if similarity >= 0.8:
                        return True

            return False

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {e}")
            return False

    async def _finalize_results(
        self,
        candidates: dict,
        processed_candidates: List[Dict],
        unmatched_characteristics: set,
        position: TenderPositions,
        min_required_points: int,
    ):
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

        logger.warning("\n" + "=" * 60)
        logger.warning("–§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")
        logger.warning("=" * 60)

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é –±–∞–ª–ª–æ–≤
        processed_candidates.sort(key=lambda x: x["points"], reverse=True)

        logger.info(f"üéØ –ü—Ä–æ—à–µ–¥—à–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(processed_candidates)}")
        logger.info(f"‚ùå –ù–µ—Å–º–µ—Ç—á–µ–Ω–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {len(unmatched_characteristics)}")

        # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        candidates["hits"]["hits"] = [
            item["candidate"] for item in processed_candidates
        ]

        # –î–æ–±–∞–≤–ª—è–µ–º –±–∞–ª–ª—ã –≤ –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
        for i, result in enumerate(processed_candidates):
            candidates["hits"]["hits"][i]["points"] = result["points"]
            candidates["hits"]["hits"][i]["matched_attributes"] = result[
                "matched_attributes"
            ]
            candidates["hits"]["hits"][i]["unmatched_attributes"] = result[
                "unmatched_attributes"
            ]

        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        report = {
            "position_title": position.title,
            "total_candidates_processed": len(processed_candidates),
            "min_required_points": min_required_points,
            "max_possible_points": len(position.attributes),
            "unmatched_characteristics": list(unmatched_characteristics),
            "top_candidates": [
                {
                    "title": result["candidate"]["_source"]["title"],
                    "points": result["points"],
                    "matched_attributes": result["matched_attributes"],
                    "unmatched_attributes": result["unmatched_attributes"],
                }
                for result in processed_candidates[:10]  # –¢–æ–ø 10
            ],
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_filename = f"shrinking_report_{position.id}_{int(time.time())}.json"
        with open(report_filename, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        logger.info(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_filename}")

        # –ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Ç–æ–ø–∞
        logger.info("\nüèÜ –¢–û–ü –ö–ê–ù–î–ò–î–ê–¢–û–í:")
        for i, result in enumerate(processed_candidates[:5], 1):
            logger.info(
                f"{i}. {result['candidate']['_source']['title']} - {result['points']} –±–∞–ª–ª–æ–≤"
            )

        if unmatched_characteristics:
            logger.warning("\n‚ùå –ù–ï–°–ú–ï–¢–ß–ï–ù–ù–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò:")
            for char in unmatched_characteristics:
                logger.warning(f"  ‚Ä¢ {char}")
