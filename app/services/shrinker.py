import json
import time
from typing import Optional, List, Dict

from app.core.logger import get_logger
from app.models.tenders import TenderPositions
from app.services.attrs_standardizer import AttrsStandardizer
from app.services.trigrammer import Trigrammer
from app.services.unit_standardizer import UnitStandardizer
from app.services.vectorizer import SemanticMatcher

logger = get_logger(name=__name__)


class Shrinker:
    def __init__(
        self,
        trigrammer: Optional[Trigrammer] = None,
        vectorizer: Optional[SemanticMatcher] = None,
        attrs_sorter: Optional[AttrsStandardizer] = None,
        unit_normalizer: Optional[UnitStandardizer] = None,
    ):
        self.trigrammer = trigrammer
        self.vectorizer = vectorizer
        self.attrs_sorter = attrs_sorter
        self.unit_normalizer = unit_normalizer

    async def shrink(self, candidates: dict, position: TenderPositions):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"""

        # === –≠–¢–ê–ü 1: –ü–û–î–ì–û–¢–û–í–ö–ê ===
        logger.warning("=" * 60)
        logger.warning("–ù–ê–ß–ê–õ–û –û–ë–†–ê–ë–û–¢–ö–ò –ü–û–ó–ò–¶–ò–ò")
        logger.warning("=" * 60)

        position_max_points = len(position.attributes)
        min_required_points = position_max_points // 2  # –ü–æ–ª–æ–≤–∏–Ω–∞ –æ—Ç –º–∞–∫—Å–∏–º—É–º–∞

        logger.info(f"üìã –ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏: {position.title}")
        logger.info(f"üìã –ö–∞—Ç–µ–≥–æ—Ä–∏—è –ø–æ–∑–∏—Ü–∏–∏: {position.category}")
        logger.info(f"üéØ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –±–∞–ª–ª—ã: {position_max_points}")
        logger.info(f"‚ö° –ú–∏–Ω–∏–º—É–º –¥–ª—è –ø—Ä–æ—Ö–æ–¥–∞: {min_required_points}")

        # –ü–∞—Ä—Å–∏–º –∞—Ç—Ä–∏–±—É—Ç—ã –ø–æ–∑–∏—Ü–∏–∏ —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π
        position_attrs = await self._parse_position_attributes(position.attributes)
        logger.critical(position_attrs)

        if len(position_attrs.get('attrs', [])) == 0:
            logger.warning("‚ùå –ù–µ—Ç –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
            return

        # === –≠–¢–ê–ü 2: –û–ë–†–ê–ë–û–¢–ö–ê –ö–ê–ù–î–ò–î–ê–¢–û–í ===
        logger.info(f"\nüîç –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(candidates['hits']['hits'])} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")

        processed_candidates = []
        unmatched_characteristics = set()

        for idx, candidate in enumerate(candidates["hits"]["hits"]):
            logger.info(f"\n--- –ö–∞–Ω–¥–∏–¥–∞—Ç {idx + 1}: {candidate['_source']['title']} ---")

            result = await self._process_single_candidate(
                candidate,
                position_attrs,
                min_required_points,
                unmatched_characteristics,
            )

            if result:
                processed_candidates.append(result)

        # === –≠–¢–ê–ü 3: –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê ===
        await self._finalize_results(
            candidates,
            processed_candidates,
            unmatched_characteristics,
            position,
            min_required_points,
        )

    async def _parse_position_attributes(self, attributes) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –ø–æ–∑–∏—Ü–∏–∏ —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –ø–æ —Ç–∏–ø–∞–º"""
        logger.info("\nüìù –ü–ê–†–°–ò–ù–ì –ê–¢–†–ò–ë–£–¢–û–í –ü–û–ó–ò–¶–ò–ò:")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä—É–ø–ø
        attrs_data = {
            "attrs": [],
        }

        for i, attr in enumerate(attributes):
            logger.info(
                f"üìä Attr {i+1}: name='{attr.name}', value='{attr.value}', "
                f"type='{getattr(attr, 'type', 'NO_TYPE')}', unit='{getattr(attr, 'unit', 'NO_UNIT')}'"
            )

        parsed_attrs = []

        for i, attr in enumerate(attributes):
            logger.info(f"\n--- –ê–¢–†–ò–ë–£–¢ –ü–û–ó–ò–¶–ò–ò {i+1}/{len(attributes)} ---")
            try:
                parsed = None
                try:
                    unit = getattr(attr, "unit", "") or ""
                    raw_string = f"{attr.name}: {attr.value} {unit}".strip()
                    logger.info(f"üîÑ Raw request: {raw_string}")
                    parsed = await self.attrs_sorter.extract_attr_data(raw_string)
                    logger.info(f"üîÑ Raw response: {parsed}")
                except Exception as e:
                    logger.error(f"failed: {e}")

                if parsed and len(parsed) > 0:
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–¥—Ç–∏–ø –¥–ª—è simple –∑–Ω–∞—á–µ–Ω–∏–π
                    original_type = parsed[0].get("type", "simple")
                    if original_type == "simple":
                        value = parsed[0].get("value", {}).get("value")
                        unit = parsed[0].get("value", {}).get("unit")
                        final_type = self._determine_value_subtype(value)
                    else:
                        final_type = original_type

                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å unit_normalizer –∏ –µ–¥–∏–Ω–∏—Ü–∞
                    normalized_parsed = parsed[0].copy()
                    if original_type == "numeric":
                        unit_value = parsed[0].get("value", {}).get("unit")
                        numeric_value = parsed[0].get("value", {}).get("value")

                        if unit_value and isinstance(numeric_value, (int, float)):
                            try:
                                logger.info(
                                    f"üîß Normalizing unit: {numeric_value} {unit_value}"
                                )
                                normalized_result = (
                                    await self.unit_normalizer.normalize_unit(
                                        str(numeric_value), unit_value
                                    )
                                )

                                if normalized_result.get("success", False):
                                    # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                                    normalized_parsed["value"]["value"] = (
                                        normalized_result.get(
                                            "normalized_value", numeric_value
                                        )
                                    )
                                    normalized_parsed["value"]["unit"] = (
                                        normalized_result.get(
                                            "normalized_unit", unit_value
                                        )
                                    )
                                    logger.info(
                                        f"‚úÖ Unit normalized: {normalized_result.get('normalized_value')} {normalized_result.get('normalized_unit')}"
                                    )
                                else:
                                    logger.warning(
                                        f"‚ö†Ô∏è Unit normalization failed for {numeric_value} {unit_value}"
                                    )
                            except Exception as e:
                                logger.error(f"üí• Error normalizing unit: {e}")
                    elif original_type == "range":
                        range_values = parsed[0].get("value", [])
                        if len(range_values) == 2:
                            for i, range_item in enumerate(range_values):
                                unit_value = range_item.get("unit")
                                numeric_value = range_item.get("value")

                                if unit_value and self.unit_normalizer and (isinstance(numeric_value, (int, float)) or numeric_value in ['_inf+', '_inf-']):
                                    try:
                                        if numeric_value in ["_inf+", "_inf-"]:
                                            # –î–ª—è –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ–¥–∏–Ω–∏—Ü—É, –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
                                            normalized_result = await self.unit_normalizer.normalize_unit(
                                                "1", unit_value
                                            )
                                            logger.info(f'normalized_result: {normalized_result}')
                                            logger.info(f'normalized_parsed: {normalized_parsed}')
                                            if normalized_result.get("success", False):
                                                normalized_parsed["value"][i]["unit"] = normalized_result.get(
                                                    "normalized_unit", unit_value
                                                )
                                                # –ó–Ω–∞—á–µ–Ω–∏–µ –æ—Å—Ç–∞–µ—Ç—Å—è –∫–∞–∫ –±—ã–ª–æ (_inf+ –∏–ª–∏ _inf-)
                                        else:
                                            # –î–ª—è –æ–±—ã—á–Ω—ã—Ö —á–∏—Å–µ–ª —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º –∏ –∑–Ω–∞—á–µ–Ω–∏–µ, –∏ –µ–¥–∏–Ω–∏—Ü—É
                                            normalized_result = await self.unit_normalizer.normalize_unit(
                                                str(numeric_value), unit_value
                                            )
                                            if normalized_result.get("success", False):
                                                normalized_parsed["value"][i][
                                                    "value"
                                                ] = normalized_result.get(
                                                    "normalized_value", numeric_value
                                                )
                                                normalized_parsed["value"][i][
                                                    "unit"
                                                ] = normalized_result.get(
                                                    "normalized_unit", unit_value
                                                )
                                    except Exception as e:
                                        logger.error(
                                            f"Error normalizing range unit: {e}"
                                        )
                    parsed_data = {
                        "parsed": normalized_parsed,
                        "type": final_type,
                    }

                    attrs_data["attrs"].append(parsed_data)

                    logger.info(f"  - –¢–∏–ø: {final_type} (–æ—Ä–∏–≥–∏–Ω–∞–ª: {original_type})")
                    logger.info(
                        f"  - –ó–Ω–∞—á–µ–Ω–∏–µ: {normalized_parsed.get('value', 'unknown')}"
                    )
                else:
                    logger.warning(
                        f"‚ùå Final parsed result: {parsed} | {attr.name}, {attr.value}"
                    )

            except Exception as e:
                logger.error(f"CRITICAL ERROR for '{attr.name}': {e}")
                logger.error(f"Exception type: {type(e)}")

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–∑–∏—Ü–∏–∏
        logger.info(f"\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û–ó–ò–¶–ò–ò:")
        logger.info(f"üìä –í—Å–µ–≥–æ –∞—Ç—Ä–∏–±—É—Ç–æ–≤: {len(attributes)}")
        logger.info(f"üìä –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—à–µ–Ω–æ: {len(attrs_data['attrs'])}")
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º:")
        for attr_type, count in type_stats.items():
            if count > 0:
                logger.info(f"  üìä {attr_type}: {count} –∞—Ç—Ä–∏–±—É—Ç–æ–≤")

        time.sleep(3)
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        attrs_data["_metadata"] = {
                "total_count": len(attrs_data["attrs"]),
                "type_stats": type_stats,
                "processing_timestamp": time.time(),
            }

        return attrs_data

    async def _process_single_candidate(
        self,
        candidate: Dict,
        position_attrs: Dict,
        min_required_points: int,
        unmatched_characteristics: set,
    ) -> Optional[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π"""

        candidate_attrs = candidate["_source"].get("attributes", [])
        position_attrs = position_attrs["attrs"]

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result = {
            "candidate": candidate,
            "points": 0,
            "max_points": len(position_attrs),
            "matched_attributes": [],
            "unmatched_attributes": [],
            "early_exit": False,
            "attribute_matching_details": {},
        }

        logger.info(
            f'üîé –ö–∞—Ç–µ–≥–æ—Ä–∏—è yandex: {candidate["_source"]["yandex_category"]} | '
            f'–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {candidate["_source"]["category"]} | '
            f"–∫–æ–ª-–≤–æ –∞—Ç—Ä–∏–±—É—Ç–æ–≤: {len(candidate_attrs)}"
        )

        # –ü–∞—Ä—Å–∏–º –∞—Ç—Ä–∏–±—É—Ç—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π
        candidate_grouped_attrs = await self._parse_candidate_attributes(
            candidate_attrs
        )

        for a, b in candidate_grouped_attrs.items():
            logger.warning(f"{a, b}")

        # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∏–ø–∞–º
        cand_metadata = candidate_grouped_attrs.get("_metadata", {})

        logger.info(f"üìä –ö–∞–Ω–¥–∏–¥–∞—Ç –ø–æ —Ç–∏–ø–∞–º: {cand_metadata.get('type_stats', {})}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        result["attribute_matching_details"] = {
            "candidate_attrs_by_type": cand_metadata.get("type_stats", {}),
            "total_position_attrs": len(position_attrs),
            "total_candidate_attrs": len(candidate_grouped_attrs["all"]),
            "type_match_strategies": {},
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –∞—Ç—Ä–∏–±—É—Ç –ø–æ–∑–∏—Ü–∏–∏
        for pos_attr in position_attrs:
            logger.info(f'pos_attr: {pos_attr}')
            logger.info(f'cand_attrs: {candidate_grouped_attrs}')
            pos_type = pos_attr.get("type", "unknown")

            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
            target_group = candidate_grouped_attrs.get(pos_type, [])
            match_found = await self._find_attribute_match_in_group(
                pos_attr, target_group, result, f"exact_type_match_{pos_type}", group_type=pos_type
            )

            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –¶–µ–ª–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –∫—Ä–æ—Å—Å-—Ç–∏–ø–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            if not match_found:
                compatible_groups = self._get_compatible_attribute_groups(
                    pos_type, candidate_grouped_attrs
                )
                logger.warning('compatible_groups')
                for group in compatible_groups:
                    logger.warning(group)
                for group_name, group_attrs in compatible_groups:
                    match_found = await self._find_attribute_match_in_group(
                        pos_attr,
                        group_attrs,
                        result,
                        f"cross_type_match_{pos_type}_vs_{group_name}",
                        group_type=group_name
                    )
                    if match_found:
                        break

            # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if match_found:
                result["points"] += 1
                logger.info(f"  ‚úÖ +1 –±–∞–ª–ª –∑–∞: {pos_attr['parsed']['name']}")
            else:
                result["unmatched_attributes"].append(pos_attr['parsed']['name'])
                unmatched_characteristics.add(pos_attr['parsed']['name'])
                logger.info(f"  ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {pos_attr['parsed']['name']}")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–Ω–Ω–µ–≥–æ –≤—ã—Ö–æ–¥–∞
            remaining_attrs = (
                len(position_attrs)
                - len(result["matched_attributes"])
                - len(result["unmatched_attributes"])
            )
            max_possible_points = result["points"] + remaining_attrs

            if max_possible_points < min_required_points:
                logger.warning(
                    f"  ‚ö° –†–∞–Ω–Ω–∏–π –≤—ã—Ö–æ–¥: –º–∞–∫—Å–∏–º—É–º –≤–æ–∑–º–æ–∂–Ω—ã—Ö –±–∞–ª–ª–æ–≤ {max_possible_points} < {min_required_points}"
                )
                result["early_exit"] = True
                break

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        logger.info(f"üìà –ò—Ç–æ–≥–æ–≤—ã–π —Å—á–µ—Ç: {result['points']}/{result['max_points']}")

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–∏–Ω–∏–º—É–º—É –±–∞–ª–ª–æ–≤
        if result["points"] < min_required_points:
            logger.warning(
                f"‚ùå –ö–∞–Ω–¥–∏–¥–∞—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω: {result['points']} < {min_required_points}"
            )
            return None

        logger.info(f"‚úÖ –ö–∞–Ω–¥–∏–¥–∞—Ç –ø—Ä–∏–Ω—è—Ç!")
        return result

    def _get_compatible_attribute_groups(
        self, pos_type: str, candidate_grouped_attrs: Dict
    ) -> List[tuple]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã—Ö –≥—Ä—É–ø–ø –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-—Ç–∏–ø–æ–≤–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        compatibility_rules = {
            "numeric": ["range"],
            "range": ["numeric"],
            "string": ["multiple", "boolean"],
            "multiple": ["string", "boolean"],
            "boolean": ["string", "multiple"],
        }

        compatible_groups = []
        target_types = compatibility_rules.get(pos_type, [])

        for target_type in target_types:
            group_attrs = candidate_grouped_attrs.get(target_type, [])
            if group_attrs:
                compatible_groups.append((target_type, group_attrs))

        logger.info(
            f"For {pos_type} found compatible groups: {[name for name, _ in compatible_groups]}"
        )
        return compatible_groups

    async def _parse_candidate_attributes(
        self, candidate_attrs: List[Dict]
    ) -> Dict[str, List[Dict]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –ø–æ —Ç–∏–ø–∞–º"""

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä—É–ø–ø
        grouped_attrs = {
            "boolean": [],
            "numeric": [],
            "string": [],
            "range": [],
            "multiple": [],
            "unknown": [],
            "all": [],
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º
        type_stats = {
            "boolean": 0,
            "numeric": 0,
            "string": 0,
            "range": 0,
            "multiple": 0,
            "unknown": 0,
        }

        for attr in candidate_attrs:
            try:
                # –ê—Ç—Ä–∏–±—É—Ç—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –£–ñ–ï –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ê–ù–´ –≤ Elasticsearch
                standardized_name = attr.get(
                    "standardized_name", attr.get("original_name", "")
                )
                standardized_value = attr.get(
                    "standardized_value", attr.get("original_value", "")
                )
                attribute_type = attr.get("attribute_type", "simple")

                # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
                if attribute_type == "simple":
                    standardized_unit = attr.get("standardized_unit")
                else:
                    # –î–ª—è range/multiple –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å unit –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
                    if (
                        isinstance(standardized_value, list)
                        and len(standardized_value) > 0
                    ):
                        first_item = standardized_value[0]
                        standardized_unit = (
                            first_item.get("unit")
                            if isinstance(first_item, dict)
                            else None
                        )
                    else:
                        standardized_unit = attr.get("standardized_unit")

                # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é —Å attrs_sorter
                parsed_structure = {
                    "name": standardized_name,
                    "type": attribute_type,
                    "value": self._convert_to_attrs_sorter_format(
                        standardized_value, standardized_unit, attribute_type
                    ),
                    "raw_data": attr,
                }

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–¥—Ç–∏–ø –¥–ª—è simple –∑–Ω–∞—á–µ–Ω–∏–π
                if attribute_type == "simple":
                    value_subtype = self._determine_value_subtype(
                        standardized_value
                    )
                    final_type = value_subtype
                else:
                    final_type = attribute_type

                parsed_attr = {
                    "parsed": parsed_structure,
                    "display_name": f"{standardized_name}: {standardized_value}",
                    "type": final_type
                }

                # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø–∞–º
                if final_type in grouped_attrs:
                    grouped_attrs[final_type].append(parsed_attr)
                    type_stats[final_type] += 1
                else:
                    grouped_attrs["unknown"].append(parsed_attr)
                    type_stats["unknown"] += 1
                    logger.warning(f"‚ö†Ô∏è Unknown attribute type: {final_type} for {attr.get('original_name', 'name does not defined')}")

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                grouped_attrs["all"].append(parsed_attr)

            except Exception as e:
                logger.error(f"üí• –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—Ç—Ä–∏–±—É—Ç–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞: {e}")
                logger.error(f"–ü—Ä–æ–±–ª–µ–º–Ω—ã–π –∞—Ç—Ä–∏–±—É—Ç: {attr}")

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        logger.info(f"üìä Converted {len(grouped_attrs['all'])} candidate attributes:")
        for attr_type, count in type_stats.items():
            if count > 0:
                logger.info(f"  üìä {attr_type}: {count} –∞—Ç—Ä–∏–±—É—Ç–æ–≤")

        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        grouped_attrs["_metadata"] = {
            "total_count": len(grouped_attrs["all"]),
            "type_stats": type_stats,
            "processing_timestamp": time.time(),
        }

        return grouped_attrs

    def _convert_to_attrs_sorter_format(self, value, unit, attr_type):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç attrs_sorter"""
        try:
            if attr_type == "simple":
                return {"value": value, "unit": unit}

            elif attr_type == "range":
                if isinstance(value, list) and len(value) == 2:
                    return [
                        {
                            "value": (
                                value[0].get("value")
                                if isinstance(value[0], dict)
                                else value[0]
                            ),
                            "unit": unit,
                        },
                        {
                            "value": (
                                value[1].get("value")
                                if isinstance(value[1], dict)
                                else value[1]
                            ),
                            "unit": unit,
                        },
                    ]
                else:
                    return [
                        {"value": value, "unit": unit},
                        {"value": value, "unit": unit},
                    ]

            elif attr_type == "multiple":
                if isinstance(value, list):
                    return [
                        {
                            "value": (
                                item.get("value") if isinstance(item, dict) else item
                            ),
                            "unit": unit,
                        }
                        for item in value
                    ]
                else:
                    return [{"value": value, "unit": unit}]

            else:
                return {"value": value, "unit": unit}

        except Exception as e:
            logger.error(f"Error converting value {value}: {e}")
            return {"value": str(value), "unit": unit}

    def _determine_value_subtype(self, value) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–¥—Ç–∏–ø–∞ –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è: boolean, numeric –∏–ª–∏ string"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ boolean
            if isinstance(value, bool):
                return "boolean"

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            if isinstance(value, (int, float)):
                return "numeric"

            # –î–ª—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            if isinstance(value, str):
                # –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ
                try:
                    cleaned_value = str(value).strip().replace(",", ".")
                    float(cleaned_value)
                    return "numeric"
                except (ValueError, TypeError):
                    pass

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±—É–ª–µ–≤—ã –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º –≤–∏–¥–µ
                boolean_values = {
                    "–¥–∞",
                    "–Ω–µ—Ç",
                    "true",
                    "false",
                    "yes",
                    "no",
                    "–µ—Å—Ç—å",
                    "–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç",
                    "–∏–º–µ–µ—Ç—Å—è",
                    "–Ω–µ –∏–º–µ–µ—Ç—Å—è",
                    "1",
                    "0",
                    "–≤–∫–ª",
                    "–≤—ã–∫–ª",
                    "–≤–∫–ª—é—á–µ–Ω–æ",
                    "–≤—ã–∫–ª—é—á–µ–Ω–æ",
                }
                if value.lower().strip() in boolean_values:
                    return "boolean"

                return "string"

            if value is None:
                return "string"

            logger.warning(f"Unknown value type for: {value} (type: {type(value)})")
            return "string"

        except Exception as e:
            logger.error(f"Error determining value subtype for {value}: {e}")
            return "string"

    async def _find_attribute_match_in_group(
        self,
        pos_attr: Dict,
        candidate_attrs_group: List[Dict],
        result: Dict,
        match_type: str,
        group_type: str
    ) -> bool:
        """–ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∞—Ç—Ä–∏–±—É—Ç–∞ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –≥—Ä—É–ø–ø–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"""

        pos_type = pos_attr.get("type")
        pos_name = pos_attr["parsed"].get("name", "")

        logger.warning(f'pos_type = {pos_type} | cand_type = {group_type}')

        for cand_attr in candidate_attrs_group:
            cand_type = group_type
            cand_name = cand_attr["parsed"].get("name", "")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
            name_similarity = await self._check_name_similarity(pos_name, cand_name)
            logger.info(f'name_similarity: {name_similarity} | {pos_name} - {cand_name}')

            if name_similarity < 0.7:
                continue

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –ø–æ —Ç–∏–ø—É –∏ –∑–Ω–∞—á–µ–Ω–∏—é
            value_match = await self._check_value_compatibility(
                pos_attr["parsed"], pos_type=pos_type, cand_parsed=cand_attr["parsed"], cand_type=cand_type
            )

            if value_match:
                result["matched_attributes"].append(
                    {
                        "position_attr": f"'{pos_attr['parsed']['name']}': {pos_attr['parsed']['value']}",
                        "candidate_attr": f"'{cand_attr['parsed']['name']}': {cand_attr['parsed']['value']}",
                        "name_similarity": name_similarity,
                        "match_type": f"{pos_attr.get('type', 'unknown')} vs {cand_attr.get('type', 'unknown')}",
                        "matching_strategy": match_type,
                        "position_attr_type": pos_attr.get("type", "unknown"),
                        "candidate_attr_type": cand_attr.get("type", "unknown"),
                    }
                )
                return True

        return False

    async def _check_name_similarity(self, name1: str, name2: str) -> float:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–π –∞—Ç—Ä–∏–±—É—Ç–æ–≤"""
        try:
            if not name1 or not name2:
                return 0.0

            similarity = await self.vectorizer.compare_two_strings(name1, name2)
            return similarity

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π: {e}")
            return 0.0

    async def _check_value_compatibility(
        self, pos_parsed: Dict, pos_type: str, cand_parsed: Dict, cand_type: str
    ) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏–π –∞—Ç—Ä–∏–±—É—Ç–æ–≤ (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        try:
            # Boolean –∑–Ω–∞—á–µ–Ω–∏—è - —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è, –∞ –Ω–µ –∑–Ω–∞—á–µ–Ω–∏—è
            if pos_type == "boolean" and cand_type == "boolean":
                return await self._compare_boolean_names(pos_parsed, cand_parsed)

            # Boolean –∫—Ä–æ—Å—Å-—Ç–∏–ø–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ - —Ç–∞–∫–∂–µ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è
            elif pos_type == "boolean" and cand_type in ["string", "multiple"]:
                return await self._compare_boolean_with_other_types(
                    pos_parsed, cand_parsed
                )

            elif pos_type in ["string", "multiple"] and cand_type == "boolean":
                return await self._compare_boolean_with_other_types(
                    cand_parsed, pos_parsed
                )

            # Numeric –∑–Ω–∞—á–µ–Ω–∏—è
            elif pos_type == "numeric" and cand_type == "numeric":
                return await self._compare_numeric_values(pos_parsed, cand_parsed)

            # String –∑–Ω–∞—á–µ–Ω–∏—è
            elif pos_type == "string" and cand_type == "string":
                return await self._compare_string_values(pos_parsed, cand_parsed)

            # –î–∏–∞–ø–∞–∑–æ–Ω—ã
            elif pos_type == "range" and cand_type == "range":
                return await self._compare_ranges(pos_parsed, cand_parsed)

            # Numeric ‚Üî Range
            elif pos_type == "numeric" and cand_type == "range":
                return await self._value_in_range(pos_parsed, cand_parsed)

            elif pos_type == "range" and cand_type == "numeric":
                return await self._value_in_range(cand_parsed, pos_parsed)

            # Multiple –∑–Ω–∞—á–µ–Ω–∏—è
            elif pos_type == "multiple" or cand_type == "multiple":
                return await self._compare_multiple_values(pos_parsed, cand_parsed)

            return False

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏–π: {e}")
            return False

    async def _compare_boolean_names(self, pos_data: Dict, cand_data: Dict) -> bool:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±—É–ª–µ–≤—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º, –∞ –Ω–µ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º"""
        try:
            pos_name = pos_data.get("name", "")
            cand_name = cand_data.get("name", "")

            if not pos_name or not cand_name:
                return False

            similarity = await self.vectorizer.compare_two_strings(pos_name, cand_name)
            logger.debug(
                f"Boolean names comparison: '{pos_name}' vs '{cand_name}' = {similarity}"
            )

            return similarity >= 0.8

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π –±—É–ª–µ–≤—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤: {e}")
            return False

    async def _compare_boolean_with_other_types(
        self, bool_data: Dict, other_data: Dict
    ) -> bool:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±—É–ª–µ–≤–æ–≥–æ –∞—Ç—Ä–∏–±—É—Ç–∞ —Å –¥—Ä—É–≥–∏–º–∏ —Ç–∏–ø–∞–º–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é"""
        try:
            bool_name = bool_data.get("name", "")
            other_name = other_data.get("name", "")

            if not bool_name or not other_name:
                return False

            similarity = await self.vectorizer.compare_two_strings(
                bool_name, other_name
            )
            logger.debug(
                f"Boolean vs other type names: '{bool_name}' vs '{other_name}' = {similarity}"
            )

            return similarity >= 0.8

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫—Ä–æ—Å—Å-—Ç–∏–ø–æ–≤–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å boolean: {e}")
            return False

    async def _compare_boolean_values(self, pos_data: Dict, cand_data: Dict) -> bool:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
        try:
            pos_value = pos_data.get("value", {}).get("value")
            cand_value = cand_data.get("value", {}).get("value")

            pos_bool = self._normalize_boolean_value(pos_value)
            cand_bool = self._normalize_boolean_value(cand_value)

            if pos_bool is not None and cand_bool is not None:
                return pos_bool == cand_bool

            return False
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –±—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {e}")
            return False

    def _normalize_boolean_value(self, value) -> bool:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è –∫ –±—É–ª–µ–≤–æ–º—É —Ç–∏–ø—É"""
        if isinstance(value, bool):
            return value

        if isinstance(value, str):
            true_values = {
                "–¥–∞",
                "true",
                "yes",
                "–µ—Å—Ç—å",
                "–∏–º–µ–µ—Ç—Å—è",
                "1",
                "–≤–∫–ª",
                "–≤–∫–ª—é—á–µ–Ω–æ",
            }
            false_values = {
                "–Ω–µ—Ç",
                "false",
                "no",
                "–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç",
                "–Ω–µ –∏–º–µ–µ—Ç—Å—è",
                "0",
                "–≤—ã–∫–ª",
                "–≤—ã–∫–ª—é—á–µ–Ω–æ",
            }

            normalized = value.lower().strip()
            if normalized in true_values:
                return True
            elif normalized in false_values:
                return False

        if isinstance(value, (int, float)):
            return bool(value)

        return None

    async def _compare_string_values(self, pos_data: Dict, cand_data: Dict) -> bool:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
        try:
            pos_value = str(pos_data.get("value", {}).get("value", ""))
            cand_value = str(cand_data.get("value", {}).get("value", ""))

            similarity = await self.vectorizer.compare_two_strings(
                pos_value, cand_value
            )
            logger.info(similarity >= 0.8)
            return similarity >= 0.8

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {e}")
            return False

    async def _compare_numeric_values(self, pos_data: Dict, cand_data: Dict) -> bool:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Å —É—á–µ—Ç–æ–º –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è"""
        pos_value = pos_data.get("value", {}).get("value")
        cand_value = cand_data.get("value", {}).get("value")
        pos_unit = pos_data.get("value", {}).get("unit")
        cand_unit = cand_data.get("value", {}).get("unit")

        try:
            if pos_unit == cand_unit:
                tolerance = 0.1
                return (
                    abs(pos_value - cand_value) / max(pos_value, cand_value, 1)
                    <= tolerance
                )

            if pos_unit and cand_unit:
                pos_normalized = await self.unit_normalizer.normalize_unit(
                    str(pos_value), pos_unit
                )
                cand_normalized = await self.unit_normalizer.normalize_unit(
                    str(cand_value), cand_unit
                )

                if pos_normalized.get("success") and cand_normalized.get("success"):
                    pos_norm_val = pos_normalized.get("normalized_value")
                    cand_norm_val = cand_normalized.get("normalized_value")

                    if pos_norm_val is not None and cand_norm_val is not None:
                        tolerance = 0.1
                        return (
                            abs(pos_norm_val - cand_norm_val)
                            / max(pos_norm_val, cand_norm_val, 1)
                            <= tolerance
                        )

            return False

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {e}")
            return False

    async def _compare_ranges(self, pos_data: Dict, cand_data: Dict) -> bool:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤"""
        try:
            pos_range = pos_data.get("value", [])
            cand_range = cand_data.get("value", [])

            logger.critical(f'pos_range: {pos_range}')
            logger.critical(f'cand_range: {cand_range}')

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü –¥–ª—è –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
            pos_unit = pos_range[0].get("unit") if pos_range else None
            cand_unit = cand_range[0].get("unit") if cand_range else None

            if (
                pos_unit != cand_unit
                and pos_unit
                and cand_unit
                and self.unit_normalizer
            ):
                try:
                    for i, item in enumerate(pos_range):
                        if isinstance(item.get("value"), (int, float)):
                            norm_result = await self.unit_normalizer.normalize_unit(
                                str(item["value"]), pos_unit
                            )
                            if norm_result.get("success"):
                                pos_range[i] = {
                                    "value": norm_result["normalized_value"],
                                    "unit": norm_result["normalized_unit"],
                                }

                    for i, item in enumerate(cand_range):
                        if isinstance(item.get("value"), (int, float)):
                            norm_result = await self.unit_normalizer.normalize_unit(
                                str(item["value"]), cand_unit
                            )
                            if norm_result.get("success"):
                                cand_range[i] = {
                                    "value": norm_result["normalized_value"],
                                    "unit": norm_result["normalized_unit"],
                                }
                except Exception as e:
                    logger.error(f"Error normalizing range units: {e}")

            if len(pos_range) < 2 or len(cand_range) < 2:
                return False

            pos_start = pos_range[0].get("value")
            pos_end = pos_range[1].get("value")
            cand_start = cand_range[0].get("value")
            cand_end = cand_range[1].get("value")

            if pos_start == "_inf-":
                pos_start = float("-inf")
            if pos_end == "_inf+":
                pos_end = float("inf")
            if cand_start == "_inf-":
                cand_start = float("-inf")
            if cand_end == "_inf+":
                cand_end = float("inf")

            return pos_start <= cand_end and cand_start <= pos_end

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤: {e}")
            return False

    @staticmethod
    async def _value_in_range(value_data: Dict, range_data: Dict) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–∏—Ç –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω"""
        try:
            value = value_data.get("value", {}).get("value")
            range_vals = range_data.get("value", [])

            if len(range_vals) < 2:
                return False
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
            value_unit = value_data.get("value", {}).get("unit")
            range_unit = range_vals[0].get("unit") if range_vals else None

            if (
                value_unit != range_unit
                and value_unit
                and range_unit
                and hasattr(value_data, "unit_normalizer")
            ):
                try:
                    if isinstance(value, (int, float)):
                        norm_result = await value_data.unit_normalizer.normalize_unit(
                            str(value), value_unit
                        )
                        if norm_result.get("success"):
                            value = norm_result["normalized_value"]

                    for i, item in enumerate(range_vals):
                        if isinstance(item.get("value"), (int, float)):
                            norm_result = (
                                await value_data.unit_normalizer.normalize_unit(
                                    str(item["value"]), range_unit
                                )
                            )
                            if norm_result.get("success"):
                                range_vals[i] = {
                                    "value": norm_result["normalized_value"],
                                    "unit": norm_result["normalized_unit"],
                                }
                except Exception as e:
                    logger.error(f"Error normalizing value-range units: {e}")

            start = range_vals[0].get("value")
            end = range_vals[1].get("value")

            if start == "_inf-":
                start = float("-inf")
            if end == "_inf+":
                end = float("inf")

            return start <= value <= end

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ: {e}")
            return False

    async def _compare_multiple_values(self, pos_data: Dict, cand_data: Dict) -> bool:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
        try:
            pos_values = pos_data.get("value", [])
            cand_values = cand_data.get("value", [])

            if not isinstance(pos_values, list):
                pos_values = [pos_values]
            if not isinstance(cand_values, list):
                cand_values = [cand_values]

            for pos_val in pos_values:
                pos_val_str = str(pos_val.get("value", pos_val)).lower()
                for cand_val in cand_values:
                    cand_val_str = str(cand_val.get("value", cand_val)).lower()

                    similarity = await self.vectorizer.compare_two_strings(
                        pos_val_str, cand_val_str
                    )
                    if similarity >= 0.8:
                        return True

            return False

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {e}")
            return False

    async def _finalize_results(
        self,
        candidates: dict,
        processed_candidates: List[Dict],
        unmatched_characteristics: set,
        position: TenderPositions,
        min_required_points: int,
    ):
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

        logger.warning("\n" + "=" * 60)
        logger.warning("–§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")
        logger.warning("=" * 60)

        processed_candidates.sort(key=lambda x: x["points"], reverse=True)

        logger.info(f"üéØ –ü—Ä–æ—à–µ–¥—à–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(processed_candidates)}")
        logger.info(f"‚ùå –ù–µ—Å–º–µ—Ç—á–µ–Ω–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {len(unmatched_characteristics)}")

        candidates["hits"]["hits"] = [
            item["candidate"] for item in processed_candidates
        ]

        for i, result in enumerate(processed_candidates):
            candidates["hits"]["hits"][i]["points"] = result["points"]
            candidates["hits"]["hits"][i]["matched_attributes"] = result[
                "matched_attributes"
            ]
            candidates["hits"]["hits"][i]["unmatched_attributes"] = result[
                "unmatched_attributes"
            ]
            candidates["hits"]["hits"][i]["attribute_matching_details"] = result[
                "attribute_matching_details"
            ]

        # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
        report = {
            "position_title": position.title,
            "total_candidates_processed": len(processed_candidates),
            "min_required_points": min_required_points,
            "max_possible_points": len(position.attributes),
            "unmatched_characteristics": list(unmatched_characteristics),
            "attribute_type_analysis": self._analyze_attribute_types(
                processed_candidates
            ),
            "top_candidates": [
                {
                    "title": result["candidate"]["_source"]["title"],
                    "points": result["points"],
                    "matched_attributes": result["matched_attributes"],
                    "unmatched_attributes": result["unmatched_attributes"],
                    "attribute_matching_details": result["attribute_matching_details"],
                }
                for result in processed_candidates[:10]
            ],
        }

        report_filename = f"shrinking_report_{position.id}_{int(time.time())}.json"
        with open(report_filename, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        logger.info(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_filename}")

        logger.info("\nüèÜ –¢–û–ü –ö–ê–ù–î–ò–î–ê–¢–û–í:")
        for i, result in enumerate(processed_candidates[:5], 1):
            logger.info(
                f"{i}. {result['candidate']['_source']['title']} - {result['points']} –±–∞–ª–ª–æ–≤"
            )

        if unmatched_characteristics:
            logger.warning("\n‚ùå –ù–ï–°–ú–ï–¢–ß–ï–ù–ù–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò:")
            for char in unmatched_characteristics:
                logger.warning(f"  ‚Ä¢ {char}")

    def _analyze_attribute_types(self, processed_candidates: List[Dict]) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –º–∞—Ç—á–∏–Ω–≥–∞ –ø–æ —Ç–∏–ø–∞–º –∞—Ç—Ä–∏–±—É—Ç–æ–≤"""
        type_analysis = {
            "boolean": {"total_matches": 0, "successful_matches": 0},
            "numeric": {"total_matches": 0, "successful_matches": 0},
            "string": {"total_matches": 0, "successful_matches": 0},
            "range": {"total_matches": 0, "successful_matches": 0},
            "multiple": {"total_matches": 0, "successful_matches": 0},
        }

        for candidate in processed_candidates:
            for match in candidate.get("matched_attributes", []):
                pos_type = match.get("position_attr_type", "unknown")
                if pos_type in type_analysis:
                    type_analysis[pos_type]["successful_matches"] += 1

        return type_analysis
