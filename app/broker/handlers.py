import time
from typing import Dict, List

from faststream import Depends
from faststream.rabbit import RabbitQueue
from sqlalchemy.ext.asyncio import AsyncSession

from app.broker.broker import broker, tender_exchange
from app.core.dependencies.services import get_tender_notifier, get_service_es_selector
from app.core.logger import get_logger
from app.core.settings import settings
from app.db.session import get_session
from app.models.tenders import TenderPositions
from app.repository.postgres import PostgresRepository
from app.services.es_selector import ElasticSelector
from app.services.publisher_service import TenderNotifier
from app.services.shrinker.shrinker_main import Shrinker

logger = get_logger(name=__name__)


@broker.subscriber(
    RabbitQueue(
        "matching_queue", durable=True, routing_key="tender.categorized"
    ),
    tender_exchange,
)
async def handle_tender_categorization(
    tender_id: int,
    tender_number=None,
    customer_name=None,
    notifier: TenderNotifier = Depends(get_tender_notifier),
    es_service: ElasticSelector = Depends(get_service_es_selector),
    session: AsyncSession = Depends(get_session),
):
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –ø–µ—Ä–µ–¥–∞–µ–º –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ shrink_service
    shrink_service = Shrinker()

    logger.info(f"–ü–æ–ª—É—á–µ–Ω —Ç–µ–Ω–¥–µ—Ä –¥–ª—è –º—ç—Ç—á–∏–Ω–≥–∞: {tender_id}")

    ts_pg = time.time()

    pg_service = PostgresRepository(session)
    positions = await pg_service.get_tender_positions_selectinload(tender_id)
    company_id: str = await pg_service.get_company_id_by_tender(tender_id)

    logger.info(f"TENDER_ID: {tender_id} | COMPANY_ID: {company_id}")

    tr_pg = time.time() - ts_pg

    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –≤—Å–µ–º –ø–æ–∑–∏—Ü–∏—è–º
    all_position_results = []

    ts_es = time.time()

    logger.info(f'–¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏—à–ª–æ –ø–æ–∑–∏—Ü–∏–π: {len(positions)}')

    for position in positions:

        # –ü–æ–ª—É—á–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏
        es_candidates = await es_service.find_candidates_for_rabbit(
            index_name=settings.ES_INDEX, position=position
        )

        # –ü—Ä–∏–º–µ–Ω—è–µ–º shrinking –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞–º
        processed_candidates = await shrink_service.shrink(candidates=es_candidates, position=position)

        # –≠–¢–ê–ü 3: –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê
        await _finalize_results(candidates=es_candidates, processed_candidates=processed_candidates, position=position)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏
        position_result = {
            "position_id": position.id,
            "position_title": position.title,
            "candidates_count": len(es_candidates["hits"]["hits"]),
            "candidates": es_candidates["hits"]["hits"],
        }
        all_position_results.append(position_result)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    final_results = {
        "tender_id": tender_id,
        "tender_number": tender_number,
        "customer_name": customer_name,
        "positions_count": len(positions),
        "results": all_position_results,
    }

    tr_es = time.time() - ts_es

    logger.info(f"–ó–∞–≤–µ—Ä—à–µ–Ω –º—ç—Ç—á–∏–Ω–≥ –¥–ª—è —Ç–µ–Ω–¥–µ—Ä–∞ {tender_id}. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–æ–∑–∏—Ü–∏–π: {len(positions)}")
    logger.info(f'–æ–ø–µ—Ä–∞—Ü–∏–∏ —Å PG: {round(tr_pg, 2)} —Å–µ–∫. | –º—ç—Ç—á–µ—Ä: {round(tr_es, 2)} —Å–µ–∫.')
    logger.info(f"{60 * '='}\n")


async def _finalize_results(
    candidates: dict,
    processed_candidates: List[Dict],
    position: TenderPositions
):
    """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    try:
        processed_candidates.sort(key=lambda x: x["points"], reverse=True)
        candidates["hits"]["hits"] = [
            item["candidate"] for item in processed_candidates
        ]
        attributes_matches_data = []
        tender_matches_data = []
        for i, result in enumerate(processed_candidates):
            tender_position_id = position.id
            tender_position_max_points = len(position.attributes)
            tender_position_score = result.get("points")
            tender_position_percentage_match_score = round(tender_position_score / tender_position_max_points * 100, 1)
            product_mongo_id = result['candidate']['_source']['id']
            # –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
            tender_match_data = {
                "tender_position_id": tender_position_id,
                "product_id": product_mongo_id,
                "match_score": tender_position_score,
                "max_match_score": tender_position_max_points,
                "percentage_match_score": tender_position_percentage_match_score,
            }
            tender_matches_data.append(tender_match_data)
            for matched_char in result['matched_attributes']:
                match_data = {
                    'tender_id': position.tender_id,
                    'tender_position_id': tender_position_id,
                    'product_mongo_id': product_mongo_id,
                    'position_attr_id': matched_char['position_attr_id'],
                    'position_attr_name': matched_char['original_position_attr_name'],
                    'position_attr_value': matched_char['original_position_attr_value'],
                    'position_attr_unit': matched_char.get('original_position_attr_unit'),
                    'product_attr_name': matched_char['original_product_attr_name'],
                    'product_attr_value': str(matched_char['original_product_attr_value']),
                }
                attributes_matches_data.append(match_data)
        async for fresh_session in get_session():
            try:
                fresh_pg_service = PostgresRepository(fresh_session)
                position_number = await fresh_pg_service.increment_processed_positions(
                    tender_id=position.tender_id
                )
                if tender_matches_data:
                    await fresh_pg_service.create_tender_matches_batch(
                        tender_matches_data
                    )
                if attributes_matches_data:
                    await fresh_pg_service.create_tender_position_attribute_matches_bulk(
                        attributes_matches_data
                    )

            except Exception as e:
                logger.error(f"Database operation failed: {e}")
                await fresh_session.rollback()
                raise

            logger.info(f"[‚Ññ{position_number}] ‚úÖ –ü–æ–∑–∏—Ü–∏—è '{position.title}' –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞! –ü–æ–¥–æ–±—Ä–∞–Ω–æ {len(processed_candidates)} —Ç–æ–≤–∞—Ä–æ–≤.\n")
        # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
        # report_filename = f"shrinking_report_{position.id}_{int(time.time())}.json"
        # with open(report_filename, "w", encoding="utf-8") as f:
        #     json.dump(report, f, ensure_ascii=False, indent=2)  # Todo: dev env only!
        # logger.info(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_filename}")
    except Exception as e:
        logger.error(e)
